import re
from bs4 import BeautifulSoup
import pandas as pd
import time
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

def get_google_maps_reviews(place_url):
    """
    Scrapes Google Maps reviews from a direct URL and returns the data in a DataFrame.
    """

    service = Service()
    options = webdriver.ChromeOptions()
    #options.add_argument('--headless')  # Run Chrome in headless mode
    driver = webdriver.Chrome(service=service, options=options)
    driver.get(place_url)

    try:
        # Esperar a que cargue la p√°gina de la comisar√≠a
        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, "DUwDvf")))

        # Obtener el nombre y la direcci√≥n
        place_name_element = driver.find_element(By.CLASS_NAME, "DUwDvf")
        place_name_text = place_name_element.text.strip()
        
        address_element = driver.find_element(By.CLASS_NAME, "Io6YTe")
        address_text = address_element.text.strip()

        # Hacer clic en la pesta√±a de rese√±as
        try:
            reviews_tab = WebDriverWait(driver, 15).until(
                EC.element_to_be_clickable((By.XPATH, "//div[contains(text(), 'Opiniones')]"))
            )
            reviews_tab.click()
        except Exception as e:
            print(f"Error al hacer clic en la pesta√±a de rese√±as: {e}")
            driver.quit()
            return pd.DataFrame()  # Retorna un DataFrame vac√≠o si falla

        # Esperar a que aparezca la secci√≥n de rese√±as
        reviews_container = WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CLASS_NAME, "m6QErb"))
        )

                # Esperar a que el contenedor de rese√±as est√© presente
        scrollable_div = WebDriverWait(driver, 15).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "div.m6QErb.DxyBCb.kA9KIf.dS8AEf.XiKgde"))
        )

        last_review_count = 0
        scroll_attempts = 0
        max_attempts = 2

        while scroll_attempts < max_attempts:
            # Hacer scroll dentro del contenedor espec√≠fico de rese√±as
            driver.execute_script("arguments[0].scrollTop = arguments[0].scrollHeight", scrollable_div)
            time.sleep(2)

            # Contar cu√°ntas rese√±as hay cargadas hasta ahora
            soup = BeautifulSoup(driver.page_source, "html.parser")
            reviews_elements = soup.find_all("div", class_="jftiEf")
            current_review_count = len(reviews_elements)

            print(f"üîç Rese√±as cargadas: {current_review_count}")

            if current_review_count == last_review_count:
                scroll_attempts += 1
                print(f"‚ö†Ô∏è No nuevas rese√±as. Intento {scroll_attempts}/{max_attempts}")
            else:
                last_review_count = current_review_count
                scroll_attempts = 0  # Resetear si hay nuevas rese√±as

        # Parsear las rese√±as
        soup = BeautifulSoup(driver.page_source, "html.parser")
        reviews_elements = soup.find_all("div", class_="jftiEf")

        reviews_data = []
        for review_element in reviews_elements:
            try:
                author_element = review_element.find("div", class_="d4r55")
                author = author_element.text.strip() if author_element else "N/A"

                review_text_element = review_element.find("span", class_="wiI7pd")
                review_text = review_text_element.text.strip() if review_text_element else "N/A"

                raw_rating = review_element.find("span", class_="kvMYJc")["aria-label"]
                rating = float(re.search(r"(\d+)", raw_rating).group(1))

                review_date_element = review_element.find("span", class_="rsqaWe")
                review_date = review_date_element.text.strip() if review_text_element else "N/A"

                  
                reviews_data.append({
                    "place": place_name_text,
                    "country": "Per√∫",
                    "departamento": "Lima",
                    "provincia": "Lima",
                    "distrito": "Lima",
                    "direcci√≥n": address_text,
                    "autor": author,
                    "rese√±a": review_text,
                    "estrellas": rating,
                    "fecha": review_date
                })
            except Exception as e:
                print(f"Error procesando una rese√±a: {e}")
                
    except Exception as e:
        print(f"Error obteniendo rese√±as de {place_url}: {e}")
        reviews_data = []

    driver.quit()
    return pd.DataFrame(reviews_data)

def scrape_reviews(category, urls):
    all_reviews = pd.DataFrame()
    for url in urls:
        reviews_df = get_google_maps_reviews(url)
        all_reviews = pd.concat([all_reviews, reviews_df], ignore_index=True)
    
    if not all_reviews.empty:
        filename = f"{category}_reviews.xlsx"
        all_reviews.to_excel(filename, index=False)
        print(f"‚úÖ Rese√±as guardadas en {filename}")
    else:
        print(f"‚ö†Ô∏è No se encontraron rese√±as para {category}.")

if __name__ == "__main__":
    categories = {
        "comisarias": [
            "https://www.google.com/maps/search/Comisaria+Mirones+Alto",
            "https://www.google.com/maps/search/Comisar√≠a+Salamanca+-+Ate",
            "https://www.google.com/maps/search/Comisaria+Pnp+Unidad+Vecinal+De+Mirones"
        ],
        "ministerios": [
            "https://www.google.com/maps/search/Ministerio+de+Relaciones+Exteriores+del+Per√∫+(RREE)",
            "https://www.google.com/maps/search/Ministerio+de+Educaci√≥n+del+Per√∫",
            "https://www.google.com/maps/search/Ministerio+de+Justicia+y+Derechos+Humanos+del+Per√∫+(MINJUS)"
            "https://www.google.com/maps/search/Ministerio+del+Interior+del+Per√∫+(MININTER)",
            "https://www.google.com/maps/search/Ministerio+de+la+Mujer+y+Poblaciones+Vulnerables"
        ],
        "cines": [
            "https://www.google.com/maps/search/Cineplanet+Centro+C√≠vico",
            "https://www.google.com/maps/search/Cineplanet+Plaza+San+Miguel",
            "https://www.google.com/maps/search/Cineplanet+Brasil",
            "https://www.google.com/maps/search/Cineplanet+Salaverry",
            "https://www.google.com/maps/search/Cinestar+UNI",
            "https://www.google.com/maps/search/CineStar+Benavides",
            "https://www.google.com/maps/search/CINESTAR+SAN+JUAN",
            "https://www.google.com/maps/search/UVK+Platino+Panorama",
            "https://www.google.com/maps/search/UVK+Multicines+El+Agustino"
        ]
    }
    
    for category, urls in categories.items():
        scrape_reviews(category, urls)
